# Full Implementation Spec: Concurrent Cache Support

## Overview

Add native concurrency support to `cache-rs` while **preserving existing API and `no_std` support**. This is achieved through:

1. **Shared Segment Pattern**: Extract algorithm logic into internal `*Segment` types
2. **Separate Concurrent Types**: New `Concurrent*Cache` types under opt-in feature flag
3. **Zero Breaking Changes**: Existing single-threaded API remains unchanged

---

## 1. Design Principles

### Non-Negotiable Requirements

| Requirement | Solution |
|-------------|----------|
| **Preserve `no_std`** | Concurrent types are behind `concurrent` feature flag |
| **No API breaking changes** | Existing `LruCache` etc. unchanged; new `ConcurrentLruCache` types |
| **No code duplication** | Shared `*Segment` types contain all algorithm logic |
| **Zero overhead for single-threaded** | No runtime dispatch; direct struct embedding |
| **Compile-time polymorphism** | Separate types, not enum-based runtime switching |

### Architecture: Shared Segment Pattern

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ               LruSegment<K,V,S> (pub(crate))            ‚îÇ
‚îÇ  Contains ALL algorithm logic - written ONCE            ‚îÇ
‚îÇ  - HashMap, List, eviction, metrics, unsafe code        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚ñ≤                    ‚ñ≤
                    ‚îÇ                    ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ     LruCache      ‚îÇ    ‚îÇ  ConcurrentLruCache    ‚îÇ
        ‚îÇ  (thin wrapper)   ‚îÇ    ‚îÇ (segments + locks)     ‚îÇ
        ‚îÇ   no_std ‚úì        ‚îÇ    ‚îÇ   std only             ‚îÇ
        ‚îÇ   ~50 LOC         ‚îÇ    ‚îÇ   ~100 LOC             ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Code Maintenance Analysis**:

| Component | Lines (est.) | Duplicated? |
|-----------|-------------|-------------|
| `*Segment` (core algorithm) | ~400 per algo | **No** - single source |
| `*Cache` wrapper | ~50 per algo | No |
| `Concurrent*Cache` wrapper | ~100 per algo | No |
| Tests for segment | ~200 per algo | **No** - shared |
| Tests for concurrent | ~100 per algo | No |

**Total new code for concurrency: ~500 lines** (all 5 concurrent wrappers)

---

## 2. API Changes Summary (v0.2.0)

### What Changes

| Aspect | Before (v0.1.x) | After (v0.2.0) |
|--------|-----------------|----------------|
| Single-threaded API | `LruCache::new()` | **Unchanged** |
| Single-threaded `get()` | `fn get(&mut self) -> Option<&V>` | **Unchanged** |
| `no_std` support | ‚úÖ | ‚úÖ **Preserved** |
| Concurrent support | ‚ùå | ‚úÖ New `ConcurrentLruCache` types |

### What's New (Additive Only)

```rust
// NEW: Concurrent types (requires feature = "concurrent")
use cache_rs::concurrent::ConcurrentLruCache;

let cache = ConcurrentLruCache::new(capacity);  // Thread-safe
let cache = ConcurrentLruCache::with_segments(capacity, 16);

// Can share across threads without Arc wrapper
cache.get(&key);  // Returns Option<V> (cloned)
cache.get_with(&key, |v| v.len());  // Zero-copy callback
```

### No Migration Required

Existing code continues to work without changes:

```rust
// This still works exactly as before
use cache_rs::LruCache;

let mut cache = LruCache::new(capacity);
cache.put("key", "value");
assert_eq!(cache.get(&"key"), Some(&"value"));  // Still returns &V
```

---

## 3. File Structure

```
src/
‚îú‚îÄ‚îÄ lib.rs                    # Re-exports, #![no_std] by default
‚îú‚îÄ‚îÄ list.rs                   # Unchanged
‚îú‚îÄ‚îÄ lru.rs                    # LruSegment (pub(crate)) + LruCache (pub)
‚îú‚îÄ‚îÄ slru.rs                   # SlruSegment + SlruCache
‚îú‚îÄ‚îÄ lfu.rs                    # LfuSegment + LfuCache
‚îú‚îÄ‚îÄ lfuda.rs                  # LfudaSegment + LfudaCache
‚îú‚îÄ‚îÄ gdsf.rs                   # GdsfSegment + GdsfCache
‚îú‚îÄ‚îÄ config/                   # Unchanged
‚îú‚îÄ‚îÄ metrics/                  # Unchanged
‚îî‚îÄ‚îÄ concurrent/               # NEW: Only compiled with feature="concurrent"
    ‚îú‚îÄ‚îÄ mod.rs                # Re-exports ConcurrentLruCache, etc.
    ‚îú‚îÄ‚îÄ lru.rs                # ConcurrentLruCache (~100 lines)
    ‚îú‚îÄ‚îÄ slru.rs               # ConcurrentSlruCache (~100 lines)
    ‚îú‚îÄ‚îÄ lfu.rs                # ConcurrentLfuCache (~100 lines)
    ‚îú‚îÄ‚îÄ lfuda.rs              # ConcurrentLfudaCache (~100 lines)
    ‚îî‚îÄ‚îÄ gdsf.rs               # ConcurrentGdsfCache (~100 lines)
```

---

## 4. Implementation Details

### 4.1. Refactor Existing Caches (Extract Segment)

Each existing cache gets refactored to extract the segment. **No API changes.**

```rust
// src/lru.rs

//! Least Recently Used (LRU) Cache Implementation
//! [Keep existing module docs unchanged]

extern crate alloc;

use crate::config::LruCacheConfig;
use crate::list::{Entry, List};
use crate::metrics::{CacheMetrics, LruCacheMetrics};
use alloc::boxed::Box;
use alloc::collections::BTreeMap;
use alloc::string::String;
use core::borrow::Borrow;
use core::hash::{BuildHasher, Hash};
use core::mem;
use core::num::NonZeroUsize;

#[cfg(feature = "hashbrown")]
use hashbrown::hash_map::DefaultHashBuilder;
#[cfg(feature = "hashbrown")]
use hashbrown::HashMap;

#[cfg(not(feature = "hashbrown"))]
use std::collections::hash_map::RandomState as DefaultHashBuilder;
#[cfg(not(feature = "hashbrown"))]
use std::collections::HashMap;

// ============================================================================
// INTERNAL SEGMENT: Contains all algorithm logic (written ONCE)
// ============================================================================

/// Internal LRU segment containing the actual cache algorithm.
/// 
/// This is shared between `LruCache` (single-threaded) and 
/// `ConcurrentLruCache` (multi-threaded).
pub(crate) struct LruSegment<K, V, S = DefaultHashBuilder> {
    config: LruCacheConfig,
    list: List<(K, V)>,
    map: HashMap<K, *mut Entry<(K, V)>, S>,
    metrics: LruCacheMetrics,
}

impl<K: Hash + Eq, V, S: BuildHasher + Default> LruSegment<K, V, S> {
    /// Creates a new LRU segment with the given capacity.
    pub(crate) fn new(capacity: NonZeroUsize) -> Self {
        Self::with_hasher(capacity, S::default())
    }
    
    /// Creates a new LRU segment with a custom hasher.
    pub(crate) fn with_hasher(capacity: NonZeroUsize, hasher: S) -> Self {
        let config = LruCacheConfig::new(capacity);
        Self {
            config,
            list: List::new(capacity),
            map: HashMap::with_capacity_and_hasher(capacity.get(), hasher),
            metrics: LruCacheMetrics::new(capacity.get() as u64 * 128),
        }
    }
    
    // All existing implementation methods move here with pub(crate) visibility
    
    pub(crate) fn get(&mut self, key: &K) -> Option<&V> {
        // Existing implementation unchanged
        if let Some(&node) = self.map.get(key) {
            self.metrics.record_hit();
            // SAFETY: node comes from our map, so it's valid
            unsafe {
                self.list.move_to_front(node);
                let (_, value) = (*node).get_value();
                Some(value)
            }
        } else {
            self.metrics.record_miss(0);
            None
        }
    }
    
    pub(crate) fn get_mut(&mut self, key: &K) -> Option<&mut V> {
        // Existing implementation unchanged
        if let Some(&node) = self.map.get(key) {
            self.metrics.record_hit();
            unsafe {
                self.list.move_to_front(node);
                let (_, value) = (*node).get_value_mut();
                Some(value)
            }
        } else {
            self.metrics.record_miss(0);
            None
        }
    }
    
    pub(crate) fn put(&mut self, key: K, value: V) -> Option<(K, V)> {
        // Existing implementation unchanged
        // ... (move existing put logic here)
    }
    
    pub(crate) fn remove<Q>(&mut self, key: &Q) -> Option<V>
    where
        K: Borrow<Q>,
        Q: Hash + Eq + ?Sized,
    {
        // Existing implementation unchanged
    }
    
    pub(crate) fn peek(&self, key: &K) -> Option<&V> {
        // Existing implementation unchanged
    }
    
    pub(crate) fn contains(&self, key: &K) -> bool {
        self.map.contains_key(key)
    }
    
    pub(crate) fn len(&self) -> usize {
        self.map.len()
    }
    
    pub(crate) fn is_empty(&self) -> bool {
        self.map.is_empty()
    }
    
    pub(crate) fn cap(&self) -> NonZeroUsize {
        self.config.capacity()
    }
    
    pub(crate) fn clear(&mut self) {
        self.list.clear();
        self.map.clear();
        self.metrics = LruCacheMetrics::new(self.config.capacity().get() as u64 * 128);
    }
    
    pub(crate) fn metrics(&self) -> &LruCacheMetrics {
        &self.metrics
    }
}

// ============================================================================
// PUBLIC CACHE: Thin wrapper over segment (NO changes to existing API)
// ============================================================================

/// An LRU (Least Recently Used) cache.
/// 
/// [Keep all existing documentation unchanged]
#[derive(Debug)]
pub struct LruCache<K, V, S = DefaultHashBuilder> {
    segment: LruSegment<K, V, S>,
}

impl<K: Hash + Eq, V: Clone, S: BuildHasher + Default> LruCache<K, V, S> {
    /// Creates a new LRU cache with the given capacity.
    /// [Keep existing docs]
    pub fn new(cap: NonZeroUsize) -> Self {
        Self {
            segment: LruSegment::new(cap),
        }
    }
    
    /// Creates a new LRU cache with a custom hasher.
    /// [Keep existing docs]  
    pub fn with_hasher(cap: NonZeroUsize, hasher: S) -> Self {
        Self {
            segment: LruSegment::with_hasher(cap, hasher),
        }
    }
    
    /// Gets a reference to the value for a key.
    /// [Keep existing docs - returns &V, NOT cloned]
    #[inline]
    pub fn get(&mut self, key: &K) -> Option<&V> {
        self.segment.get(key)
    }
    
    /// Gets a mutable reference to the value for a key.
    /// [Keep existing docs]
    #[inline]
    pub fn get_mut(&mut self, key: &K) -> Option<&mut V> {
        self.segment.get_mut(key)
    }
    
    /// Inserts a key-value pair into the cache.
    /// [Keep existing docs]
    #[inline]
    pub fn put(&mut self, key: K, value: V) -> Option<(K, V)> {
        self.segment.put(key, value)
    }
    
    /// Removes a key from the cache.
    /// [Keep existing docs]
    #[inline]
    pub fn remove<Q>(&mut self, key: &Q) -> Option<V>
    where
        K: Borrow<Q>,
        Q: Hash + Eq + ?Sized,
    {
        self.segment.remove(key)
    }
    
    /// Peeks at a value without updating recency.
    #[inline]
    pub fn peek(&self, key: &K) -> Option<&V> {
        self.segment.peek(key)
    }
    
    /// Returns true if the cache contains the key.
    #[inline]
    pub fn contains(&self, key: &K) -> bool {
        self.segment.contains(key)
    }
    
    /// Returns the number of items in the cache.
    #[inline]
    pub fn len(&self) -> usize {
        self.segment.len()
    }
    
    /// Returns true if the cache is empty.
    #[inline]
    pub fn is_empty(&self) -> bool {
        self.segment.is_empty()
    }
    
    /// Returns the capacity of the cache.
    #[inline]
    pub fn cap(&self) -> NonZeroUsize {
        self.segment.cap()
    }
    
    /// Clears the cache.
    #[inline]
    pub fn clear(&mut self) {
        self.segment.clear()
    }
}

impl<K, V, S> CacheMetrics for LruCache<K, V, S> {
    fn metrics(&self) -> BTreeMap<String, f64> {
        self.segment.metrics().to_btree_map()
    }
    
    fn algorithm_name(&self) -> &'static str {
        "LRU"
    }
}

// Keep all existing tests unchanged
#[cfg(test)]
mod tests {
    // All existing tests work without modification
}
```

### 4.2. New Concurrent Module

```rust
// src/concurrent/mod.rs

//! Concurrent Cache Implementations
//!
//! This module provides thread-safe versions of all cache algorithms using
//! fine-grained locking with segmentation. Each cache is divided into multiple
//! independent segments, allowing concurrent access to different keys.
//!
//! # Usage
//!
//! ```rust
//! use cache_rs::concurrent::ConcurrentLruCache;
//! use std::sync::Arc;
//! use std::thread;
//!
//! let cache = Arc::new(ConcurrentLruCache::new(
//!     core::num::NonZeroUsize::new(1000).unwrap()
//! ));
//!
//! let cache_clone = Arc::clone(&cache);
//! thread::spawn(move || {
//!     cache_clone.put("key", "value");
//! });
//! ```
//!
//! # Performance Characteristics
//!
//! - Operations on different keys can proceed in parallel if they hash to different segments
//! - Default segment count is based on available CPUs (capped at 32)
//! - Use `with_segments()` for explicit control over segment count
//! - Memory overhead: ~O(segments) for lock structures
//!
//! # Thread Safety
//!
//! All concurrent cache types implement `Send + Sync` and can be safely
//! shared across threads using `Arc`.

mod lru;
mod slru;
mod lfu;
mod lfuda;
mod gdsf;

pub use lru::ConcurrentLruCache;
pub use slru::ConcurrentSlruCache;
pub use lfu::ConcurrentLfuCache;
pub use lfuda::ConcurrentLfudaCache;
pub use gdsf::ConcurrentGdsfCache;
```

### 4.3. Concurrent LRU Implementation

```rust
// src/concurrent/lru.rs

//! Concurrent LRU Cache Implementation
//!
//! Thread-safe LRU cache using segmented storage with fine-grained locking.

use crate::lru::LruSegment;
use crate::metrics::CacheMetrics;
use alloc::collections::BTreeMap;
use alloc::string::String;
use core::hash::{BuildHasher, Hash};
use core::num::NonZeroUsize;
use parking_lot::RwLock;
use std::sync::Arc;

#[cfg(feature = "hashbrown")]
use hashbrown::hash_map::DefaultHashBuilder;

#[cfg(not(feature = "hashbrown"))]
use std::collections::hash_map::RandomState as DefaultHashBuilder;

/// A thread-safe LRU cache with segmented storage.
///
/// This cache divides its storage into multiple independent segments,
/// each protected by its own lock. This allows concurrent access to
/// different keys that hash to different segments.
///
/// # Examples
///
/// ```rust
/// use cache_rs::concurrent::ConcurrentLruCache;
/// use std::sync::Arc;
/// use std::thread;
/// use core::num::NonZeroUsize;
///
/// let cache = Arc::new(ConcurrentLruCache::new(
///     NonZeroUsize::new(1000).unwrap()
/// ));
///
/// // Spawn multiple threads
/// let handles: Vec<_> = (0..4).map(|i| {
///     let cache = Arc::clone(&cache);
///     thread::spawn(move || {
///         for j in 0..100 {
///             cache.put(i * 100 + j, j);
///         }
///     })
/// }).collect();
///
/// for h in handles {
///     h.join().unwrap();
/// }
/// ```
///
/// # Performance
///
/// - **Get/Put/Remove**: O(1) average, plus lock acquisition time
/// - **Parallelism**: Up to N concurrent operations (where N = segment count)
/// - **Contention**: Minimal when key distribution is uniform
///
/// # Segment Count Guidelines
///
/// | Use Case | Recommended Segments |
/// |----------|---------------------|
/// | Low concurrency (1-4 threads) | 4-8 |
/// | Medium concurrency (4-16 threads) | 8-16 |
/// | High concurrency (16+ threads) | 16-32 |
/// | Small caches (< 1000 items) | 4-8 |
pub struct ConcurrentLruCache<K, V, S = DefaultHashBuilder> {
    segments: Box<[RwLock<LruSegment<K, V, S>>]>,
    segment_mask: usize,
    hasher_builder: S,
}

impl<K, V, S> ConcurrentLruCache<K, V, S>
where
    K: Hash + Eq + Clone,
    V: Clone,
    S: BuildHasher + Default + Clone,
{
    /// Creates a new concurrent LRU cache with automatic segment count.
    ///
    /// The number of segments is set to `min(num_cpus, 32)` rounded up
    /// to the next power of two, with a minimum based on capacity.
    ///
    /// # Examples
    ///
    /// ```rust
    /// use cache_rs::concurrent::ConcurrentLruCache;
    /// use core::num::NonZeroUsize;
    ///
    /// let cache: ConcurrentLruCache<String, i32> = ConcurrentLruCache::new(
    ///     NonZeroUsize::new(10000).unwrap()
    /// );
    /// ```
    pub fn new(capacity: NonZeroUsize) -> Self {
        let segment_count = Self::optimal_segment_count(capacity.get());
        Self::with_segments(capacity, segment_count)
    }
    
    /// Creates a new concurrent LRU cache with explicit segment count.
    ///
    /// The segment count will be rounded up to the next power of two.
    /// Each segment will have approximately `capacity / segments` items.
    ///
    /// # Arguments
    ///
    /// * `capacity` - Total cache capacity (divided among segments)
    /// * `segments` - Number of segments (will be rounded to power of 2)
    ///
    /// # Examples
    ///
    /// ```rust
    /// use cache_rs::concurrent::ConcurrentLruCache;
    /// use core::num::NonZeroUsize;
    ///
    /// // Create cache with 16 segments
    /// let cache: ConcurrentLruCache<String, i32> = ConcurrentLruCache::with_segments(
    ///     NonZeroUsize::new(10000).unwrap(),
    ///     16
    /// );
    /// ```
    pub fn with_segments(capacity: NonZeroUsize, segments: usize) -> Self {
        let segment_count = segments.next_power_of_two().max(1);
        let per_segment_cap = NonZeroUsize::new(
            (capacity.get() + segment_count - 1) / segment_count
        ).unwrap_or(NonZeroUsize::new(1).unwrap());
        
        let segments: Vec<_> = (0..segment_count)
            .map(|_| RwLock::new(LruSegment::new(per_segment_cap)))
            .collect();
        
        Self {
            segments: segments.into_boxed_slice(),
            segment_mask: segment_count - 1,
            hasher_builder: S::default(),
        }
    }
    
    /// Calculates optimal segment count based on capacity and CPU count.
    fn optimal_segment_count(capacity: usize) -> usize {
        let by_capacity = (capacity / 64).max(1);  // At least 64 items per segment
        let by_cpus = num_cpus::get().min(32);     // Cap at 32 segments
        by_capacity.min(by_cpus).next_power_of_two()
    }
    
    /// Hashes a key to determine its segment index.
    #[inline]
    fn segment_index(&self, key: &K) -> usize {
        use core::hash::Hasher;
        let mut hasher = self.hasher_builder.build_hasher();
        key.hash(&mut hasher);
        (hasher.finish() as usize) & self.segment_mask
    }
    
    /// Gets a clone of the value for a key.
    ///
    /// Returns `None` if the key is not present. Updates the recency of the key.
    ///
    /// # Note
    ///
    /// This method returns a cloned value because references cannot be held
    /// across lock boundaries. Use `get_with()` for zero-copy access.
    ///
    /// # Examples
    ///
    /// ```rust
    /// let cache = ConcurrentLruCache::new(NonZeroUsize::new(100).unwrap());
    /// cache.put("key", "value".to_string());
    /// assert_eq!(cache.get(&"key"), Some("value".to_string()));
    /// ```
    pub fn get(&self, key: &K) -> Option<V> {
        let idx = self.segment_index(key);
        let mut segment = self.segments[idx].write();
        segment.get(key).cloned()
    }
    
    /// Gets a value with zero-copy access via callback.
    ///
    /// The callback is invoked while holding the segment lock, allowing
    /// zero-copy access to the value. Useful for large values or when
    /// you only need to read part of the value.
    ///
    /// # Examples
    ///
    /// ```rust
    /// let cache = ConcurrentLruCache::new(NonZeroUsize::new(100).unwrap());
    /// cache.put("key", vec![1, 2, 3, 4, 5]);
    ///
    /// // Extract length without cloning the entire vector
    /// let len = cache.get_with(&"key", |v| v.len());
    /// assert_eq!(len, Some(5));
    /// ```
    pub fn get_with<F, R>(&self, key: &K, f: F) -> Option<R>
    where
        F: FnOnce(&V) -> R,
    {
        let idx = self.segment_index(key);
        let mut segment = self.segments[idx].write();
        segment.get(key).map(f)
    }
    
    /// Inserts a key-value pair into the cache.
    ///
    /// If the segment is at capacity, the least recently used item
    /// in that segment is evicted. Returns the evicted key-value pair
    /// if eviction occurred.
    ///
    /// # Examples
    ///
    /// ```rust
    /// let cache = ConcurrentLruCache::new(NonZeroUsize::new(2).unwrap());
    /// cache.put("a", 1);
    /// cache.put("b", 2);
    /// let evicted = cache.put("c", 3);  // May evict "a" or "b"
    /// ```
    pub fn put(&self, key: K, value: V) -> Option<(K, V)> {
        let idx = self.segment_index(&key);
        let mut segment = self.segments[idx].write();
        segment.put(key, value)
    }
    
    /// Removes a key from the cache.
    ///
    /// Returns the value if the key was present.
    pub fn remove(&self, key: &K) -> Option<V> {
        let idx = self.segment_index(key);
        let mut segment = self.segments[idx].write();
        segment.remove(key)
    }
    
    /// Returns true if the cache contains the key.
    pub fn contains(&self, key: &K) -> bool {
        let idx = self.segment_index(key);
        let segment = self.segments[idx].read();
        segment.contains(key)
    }
    
    /// Returns the approximate number of items in the cache.
    ///
    /// This requires acquiring read locks on all segments, so it may
    /// not reflect concurrent modifications.
    pub fn len(&self) -> usize {
        self.segments.iter()
            .map(|seg| seg.read().len())
            .sum()
    }
    
    /// Returns true if the cache is empty.
    pub fn is_empty(&self) -> bool {
        self.segments.iter()
            .all(|seg| seg.read().is_empty())
    }
    
    /// Returns the total capacity across all segments.
    pub fn capacity(&self) -> usize {
        self.segments.iter()
            .map(|seg| seg.read().cap().get())
            .sum()
    }
    
    /// Returns the number of segments.
    pub fn segment_count(&self) -> usize {
        self.segments.len()
    }
    
    /// Clears all items from the cache.
    ///
    /// This acquires write locks on all segments sequentially.
    pub fn clear(&self) {
        for segment in self.segments.iter() {
            segment.write().clear();
        }
    }
}

// Thread-safety: segments are protected by RwLock
unsafe impl<K: Send, V: Send, S: Send> Send for ConcurrentLruCache<K, V, S> {}
unsafe impl<K: Send + Sync, V: Send + Sync, S: Send + Sync> Sync for ConcurrentLruCache<K, V, S> {}

impl<K, V, S> CacheMetrics for ConcurrentLruCache<K, V, S>
where
    K: Hash + Eq,
    S: BuildHasher,
{
    fn metrics(&self) -> BTreeMap<String, f64> {
        let mut aggregated = BTreeMap::new();
        let mut total_hits = 0.0;
        let mut total_misses = 0.0;
        
        for segment in self.segments.iter() {
            let seg_metrics = segment.read().metrics().to_btree_map();
            for (key, value) in seg_metrics {
                if key == "hits" {
                    total_hits += value;
                } else if key == "misses" {
                    total_misses += value;
                } else if key == "hit_rate" {
                    // Skip - we'll recalculate
                } else {
                    // Sum other metrics
                    *aggregated.entry(key).or_insert(0.0) += value;
                }
            }
        }
        
        // Add aggregated hits/misses and recalculate hit rate
        aggregated.insert("hits".into(), total_hits);
        aggregated.insert("misses".into(), total_misses);
        let total = total_hits + total_misses;
        if total > 0.0 {
            aggregated.insert("hit_rate".into(), total_hits / total);
        } else {
            aggregated.insert("hit_rate".into(), 0.0);
        }
        
        aggregated
    }
    
    fn algorithm_name(&self) -> &'static str {
        "ConcurrentLRU"
    }
}

impl<K, V, S> std::fmt::Debug for ConcurrentLruCache<K, V, S> {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        f.debug_struct("ConcurrentLruCache")
            .field("len", &self.len())
            .field("capacity", &self.capacity())
            .field("segments", &self.segment_count())
            .finish()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::sync::Arc;
    use std::thread;

    #[test]
    fn test_basic_operations() {
        let cache = ConcurrentLruCache::new(NonZeroUsize::new(100).unwrap());
        
        cache.put("a", 1);
        assert_eq!(cache.get(&"a"), Some(1));
        
        cache.put("b", 2);
        assert_eq!(cache.get(&"b"), Some(2));
        
        assert_eq!(cache.remove(&"a"), Some(1));
        assert_eq!(cache.get(&"a"), None);
    }
    
    #[test]
    fn test_concurrent_reads() {
        let cache = Arc::new(ConcurrentLruCache::new(NonZeroUsize::new(1000).unwrap()));
        
        // Pre-populate
        for i in 0..1000 {
            cache.put(i, i * 2);
        }
        
        let handles: Vec<_> = (0..8)
            .map(|_| {
                let cache = Arc::clone(&cache);
                thread::spawn(move || {
                    for i in 0..1000 {
                        assert_eq!(cache.get(&i), Some(i * 2));
                    }
                })
            })
            .collect();
        
        for h in handles {
            h.join().unwrap();
        }
    }
    
    #[test]
    fn test_concurrent_writes() {
        let cache = Arc::new(ConcurrentLruCache::new(NonZeroUsize::new(10000).unwrap()));
        
        let handles: Vec<_> = (0..8)
            .map(|thread_id| {
                let cache = Arc::clone(&cache);
                thread::spawn(move || {
                    for i in 0..1000 {
                        let key = thread_id * 1000 + i;
                        cache.put(key, key);
                    }
                })
            })
            .collect();
        
        for h in handles {
            h.join().unwrap();
        }
        
        assert_eq!(cache.len(), 8000);
    }
    
    #[test]
    fn test_get_with_callback() {
        let cache = ConcurrentLruCache::new(NonZeroUsize::new(100).unwrap());
        cache.put("key", vec![1, 2, 3, 4, 5]);
        
        let len = cache.get_with(&"key", |v| v.len());
        assert_eq!(len, Some(5));
        
        let sum: Option<i32> = cache.get_with(&"key", |v| v.iter().sum());
        assert_eq!(sum, Some(15));
    }
    
    #[test]
    fn test_segment_isolation() {
        // Verify that operations on different segments don't interfere
        let cache = Arc::new(ConcurrentLruCache::with_segments(
            NonZeroUsize::new(1000).unwrap(),
            16
        ));
        
        let handles: Vec<_> = (0..16)
            .map(|i| {
                let cache = Arc::clone(&cache);
                thread::spawn(move || {
                    // Each thread works with keys that likely hash to its segment
                    for j in 0..100 {
                        let key = i * 1000 + j;
                        cache.put(key, key);
                        assert_eq!(cache.get(&key), Some(key));
                    }
                })
            })
            .collect();
        
        for h in handles {
            h.join().unwrap();
        }
    }
}
```

### 4.4. Similar Implementations for Other Algorithms

Apply the same pattern to SLRU, LFU, LFUDA, and GDSF:

```rust
// src/concurrent/slru.rs - ConcurrentSlruCache
// src/concurrent/lfu.rs - ConcurrentLfuCache  
// src/concurrent/lfuda.rs - ConcurrentLfudaCache
// src/concurrent/gdsf.rs - ConcurrentGdsfCache
```

Each follows the same pattern:
1. Use the existing `*Segment` type
2. Wrap in `Box<[RwLock<*Segment>]>`
3. Implement segment-aware operations
4. `get()` returns cloned value, `get_with()` for zero-copy

---

## 5. Update `Cargo.toml`

```toml
[package]
name = "cache-rs"
version = "0.2.0"
edition = "2021"
rust-version = "1.74.0"
authors = ["sigsegved"]
categories = ["caching", "no-std"]  # Keep no-std category
description = "A high-performance, memory-efficient cache implementation supporting multiple eviction policies including LRU, LFU, LFUDA, SLRU and GDSF"
readme = "README.md"
repository = "https://github.com/sigsegved/cache-rs"
homepage = "https://github.com/sigsegved/cache-rs"
documentation = "https://docs.rs/cache-rs"
license = "MIT"
keywords = ["cache", "eviction", "lru", "memory", "data-structures"]
exclude = ["/.github", "/.gitignore"]

[features]
default = ["hashbrown"]
hashbrown = ["dep:hashbrown"]
nightly = ["hashbrown/nightly"]
std = []

# NEW: Opt-in concurrency support
concurrent = ["dep:parking_lot", "dep:num_cpus"]

[dependencies]
hashbrown = { version = "0.14.5", optional = true }

# Only required when concurrent feature is enabled
parking_lot = { version = "0.12", optional = true }
num_cpus = { version = "1.16", optional = true }

[dev-dependencies]
scoped_threadpool = "0.1.*"
stats_alloc = "0.1.*"
criterion = "0.5.1"

[[bench]]
name = "criterion_benchmarks"
harness = false

[[bench]]
name = "concurrent_benchmarks"
harness = false
required-features = ["concurrent"]
```

---

## 6. Update `src/lib.rs`

```rust
//! # Cache
//!
//! A collection of high-performance, memory-efficient cache implementations supporting various eviction policies.
//!
//! This crate provides cache implementations optimized for performance and memory usage that can be used
//! in both std and no_std environments. All cache operations (`get`, `get_mut`, `put`, and `remove`)
//! have O(1) time complexity.
//!
//! ## Available Cache Algorithms
//!
//! | Algorithm | Description | Best Use Case |
//! |-----------|-------------|---------------|
//! | [`LruCache`] | Least Recently Used | General purpose, recency-based access patterns |
//! | [`SlruCache`] | Segmented LRU | Mixed access patterns with both hot and cold items |
//! | [`LfuCache`] | Least Frequently Used | Frequency-based access patterns |
//! | [`LfudaCache`] | LFU with Dynamic Aging | Long-running caches with changing popularity |
//! | [`GdsfCache`] | Greedy Dual Size Frequency | CDNs and size-aware caching |
//!
//! ## Concurrency Support
//!
//! For thread-safe caches, enable the `concurrent` feature and use the types in the
//! [`concurrent`] module:
//!
//! ```toml
//! [dependencies]
//! cache-rs = { version = "0.2", features = ["concurrent"] }
//! ```
//!
//! ```rust,ignore
//! use cache_rs::concurrent::ConcurrentLruCache;
//! use std::sync::Arc;
//!
//! let cache = Arc::new(ConcurrentLruCache::new(capacity));
//! // Share across threads...
//! ```
//!
//! ## No-std Support
//!
//! This crate works in `no_std` environments by default. The `concurrent` feature
//! requires `std`.

#![no_std]

#[cfg(test)]
extern crate scoped_threadpool;

extern crate alloc;

// Internal infrastructure
pub(crate) mod list;

// Configuration
pub mod config;

// Metrics
pub mod metrics;

// Cache implementations (all no_std compatible)
pub mod lru;
pub mod slru;
pub mod lfu;
pub mod lfuda;
pub mod gdsf;

// Concurrent module (requires std)
#[cfg(feature = "concurrent")]
pub mod concurrent;

// Re-exports
pub use config::{
    GdsfCacheConfig, LfuCacheConfig, LfudaCacheConfig, LruCacheConfig, SlruCacheConfig,
};
pub use gdsf::GdsfCache;
pub use lfu::LfuCache;
pub use lfuda::LfudaCache;
pub use lru::LruCache;
pub use metrics::{CacheMetrics, CoreCacheMetrics};
pub use slru::SlruCache;

#[cfg(feature = "concurrent")]
pub use concurrent::{
    ConcurrentGdsfCache, ConcurrentLfuCache, ConcurrentLfudaCache,
    ConcurrentLruCache, ConcurrentSlruCache,
};
```

---

## 7. Benchmark Suite

### 7.1. Concurrent Benchmarks

Create `benches/concurrent_benchmarks.rs`:

```rust
//! Concurrent cache benchmarks
//!
//! Tests cache performance under multi-threaded load.
//! 
//! Run with: cargo bench --bench concurrent_benchmarks --features concurrent

use cache_rs::concurrent::{ConcurrentLruCache, ConcurrentSlruCache};
use criterion::{black_box, criterion_group, criterion_main, BenchmarkId, Criterion};
use std::num::NonZeroUsize;
use std::sync::Arc;
use std::thread;

const CACHE_SIZE: usize = 10_000;
const OPS_PER_THREAD: usize = 10_000;

fn concurrent_reads(c: &mut Criterion) {
    let mut group = c.benchmark_group("concurrent_reads");
    
    for num_threads in [1, 2, 4, 8, 16] {
        group.bench_with_input(
            BenchmarkId::new("ConcurrentLRU", num_threads),
            &num_threads,
            |b, &num_threads| {
                let cache = {
                    let cache = ConcurrentLruCache::new(
                        NonZeroUsize::new(CACHE_SIZE).unwrap()
                    );
                    for i in 0..CACHE_SIZE {
                        cache.put(i, i);
                    }
                    Arc::new(cache)
                };
                
                b.iter(|| {
                    let handles: Vec<_> = (0..num_threads)
                        .map(|_| {
                            let cache = Arc::clone(&cache);
                            thread::spawn(move || {
                                for i in 0..OPS_PER_THREAD {
                                    black_box(cache.get(&(i % CACHE_SIZE)));
                                }
                            })
                        })
                        .collect();
                    
                    for handle in handles {
                        handle.join().unwrap();
                    }
                });
            },
        );
    }
    
    group.finish();
}

fn concurrent_writes(c: &mut Criterion) {
    let mut group = c.benchmark_group("concurrent_writes");
    
    for num_threads in [1, 2, 4, 8, 16] {
        group.bench_with_input(
            BenchmarkId::new("ConcurrentLRU", num_threads),
            &num_threads,
            |b, &num_threads| {
                b.iter(|| {
                    let cache = Arc::new(ConcurrentLruCache::new(
                        NonZeroUsize::new(CACHE_SIZE).unwrap()
                    ));
                    
                    let handles: Vec<_> = (0..num_threads)
                        .map(|thread_id| {
                            let cache = Arc::clone(&cache);
                            thread::spawn(move || {
                                for i in 0..OPS_PER_THREAD {
                                    let key = thread_id * OPS_PER_THREAD + i;
                                    black_box(cache.put(key, key));
                                }
                            })
                        })
                        .collect();
                    
                    for handle in handles {
                        handle.join().unwrap();
                    }
                });
            },
        );
    }
    
    group.finish();
}

fn concurrent_mixed(c: &mut Criterion) {
    let mut group = c.benchmark_group("concurrent_mixed");
    
    for num_threads in [1, 2, 4, 8, 16] {
        group.bench_with_input(
            BenchmarkId::new("ConcurrentLRU_75read_25write", num_threads),
            &num_threads,
            |b, &num_threads| {
                let cache = {
                    let cache = ConcurrentLruCache::new(
                        NonZeroUsize::new(CACHE_SIZE).unwrap()
                    );
                    for i in 0..CACHE_SIZE / 2 {
                        cache.put(i, i);
                    }
                    Arc::new(cache)
                };
                
                b.iter(|| {
                    let handles: Vec<_> = (0..num_threads)
                        .map(|_| {
                            let cache = Arc::clone(&cache);
                            thread::spawn(move || {
                                for i in 0..OPS_PER_THREAD {
                                    if i % 4 == 0 {
                                        black_box(cache.put(i % CACHE_SIZE, i));
                                    } else {
                                        black_box(cache.get(&(i % CACHE_SIZE)));
                                    }
                                }
                            })
                        })
                        .collect();
                    
                    for handle in handles {
                        handle.join().unwrap();
                    }
                });
            },
        );
    }
    
    group.finish();
}

fn segment_count_comparison(c: &mut Criterion) {
    let mut group = c.benchmark_group("segment_comparison");
    
    for segments in [1, 2, 4, 8, 16, 32] {
        group.bench_with_input(
            BenchmarkId::new("ConcurrentLRU_8threads", segments),
            &segments,
            |b, &segments| {
                let cache = {
                    let cache = ConcurrentLruCache::with_segments(
                        NonZeroUsize::new(CACHE_SIZE).unwrap(),
                        segments,
                    );
                    for i in 0..CACHE_SIZE {
                        cache.put(i, i);
                    }
                    Arc::new(cache)
                };
                
                b.iter(|| {
                    let handles: Vec<_> = (0..8)
                        .map(|_| {
                            let cache = Arc::clone(&cache);
                            thread::spawn(move || {
                                for i in 0..OPS_PER_THREAD {
                                    if i % 4 == 0 {
                                        black_box(cache.put(i % CACHE_SIZE, i));
                                    } else {
                                        black_box(cache.get(&(i % CACHE_SIZE)));
                                    }
                                }
                            })
                        })
                        .collect();
                    
                    for handle in handles {
                        handle.join().unwrap();
                    }
                });
            },
        );
    }
    
    group.finish();
}

criterion_group!(
    benches,
    concurrent_reads,
    concurrent_writes,
    concurrent_mixed,
    segment_count_comparison
);
criterion_main!(benches);
```

---

## 8. Documentation Updates

### 8.1. Update `README.md`

Add a new section for concurrency:

```markdown
## Concurrency Support

For thread-safe caches, enable the `concurrent` feature:

```toml
[dependencies]
cache-rs = { version = "0.2", features = ["concurrent"] }
```

```rust
use cache_rs::concurrent::ConcurrentLruCache;
use std::sync::Arc;
use std::thread;
use core::num::NonZeroUsize;

// Create a concurrent cache
let cache = Arc::new(ConcurrentLruCache::new(
    NonZeroUsize::new(10000).unwrap()
));

// Share across threads
let handles: Vec<_> = (0..8).map(|i| {
    let cache = Arc::clone(&cache);
    thread::spawn(move || {
        for j in 0..1000 {
            cache.put(i * 1000 + j, j);
        }
    })
}).collect();

for h in handles {
    h.join().unwrap();
}

// Zero-copy access with callbacks
let sum = cache.get_with(&"key", |values| values.iter().sum::<i32>());
```

### Concurrent Performance

| Threads | Segments | Ops/sec (mixed workload) |
|---------|----------|--------------------------|
| 1 | 1 | ~1.1M |
| 8 | 8 | ~6.5M |
| 8 | 16 | ~7.8M |
| 16 | 16 | ~12M |

Note: The single-threaded `LruCache` remains the fastest option for non-concurrent use cases.
```

### 8.2. Update `CHANGELOG.md`

```markdown
# Changelog

## [0.2.0] - 2026-01-XX

### üöÄ Added

- **Concurrent Cache Types**: New thread-safe cache implementations
  - `ConcurrentLruCache`, `ConcurrentSlruCache`, `ConcurrentLfuCache`, 
    `ConcurrentLfudaCache`, `ConcurrentGdsfCache`
  - Fine-grained locking with configurable segment count
  - Zero-copy `get_with()` callback API
  - Requires `concurrent` feature flag

- **New Feature Flag**: `concurrent`
  - Enables thread-safe cache types
  - Adds `parking_lot` and `num_cpus` dependencies
  - Requires `std` (does not affect default `no_std` support)

- **Concurrent Benchmarks**: New benchmark suite for multi-threaded performance
  - Run with `cargo bench --bench concurrent_benchmarks --features concurrent`

### ‚ôªÔ∏è Refactored

- Internal architecture uses shared segment types
  - `LruSegment`, `SlruSegment`, `LfuSegment`, `LfudaSegment`, `GdsfSegment`
  - Eliminates code duplication between single and concurrent variants
  - No changes to public API

### üìù Notes

- **No breaking changes**: Existing API remains unchanged
- **`no_std` preserved**: Default build still supports `no_std`
- **Zero overhead**: Single-threaded caches have no additional overhead

**Full Changelog**: https://github.com/sigsegved/cache-rs/compare/v0.1.1...v0.2.0
```

---

## 9. Testing Strategy

### 9.1. Test Checklist

- [ ] All existing unit tests pass unchanged
- [ ] `no_std` compilation test passes: `cargo build --no-default-features --target thumbv6m-none-eabi`
- [ ] New concurrent tests pass
- [ ] Concurrent benchmarks run without errors
- [ ] MIRI clean for segment code
- [ ] No clippy warnings

### 9.2. Test Commands

```bash
# Existing tests (no changes needed)
cargo test --all

# Verify no_std still works
cargo build --no-default-features --target thumbv6m-none-eabi

# Concurrent feature tests
cargo test --features concurrent

# Concurrent benchmarks
cargo bench --bench concurrent_benchmarks --features concurrent

# Full validation
cargo fmt --all -- --check
cargo clippy --all-targets --all-features -- -D warnings
cargo doc --no-deps --document-private-items

# MIRI (for unsafe code)
cargo +nightly miri test
cargo +nightly miri test --features concurrent
```

---

## 10. Implementation Order

### Phase 1: Segment Extraction (Week 1)
1. ‚úÖ Refactor `LruCache` ‚Üí extract `LruSegment`
2. ‚úÖ Verify all existing tests pass
3. ‚úÖ Verify `no_std` build still works
4. ‚úÖ Repeat for SLRU, LFU, LFUDA, GDSF

### Phase 2: Concurrent Module (Week 2)
5. ‚úÖ Create `src/concurrent/mod.rs`
6. ‚úÖ Implement `ConcurrentLruCache`
7. ‚úÖ Add concurrent LRU tests
8. ‚úÖ Implement remaining concurrent types

### Phase 3: Benchmarks & Testing (Week 2-3)
9. ‚úÖ Create concurrent benchmark suite
10. ‚úÖ Validate thread safety with stress tests
11. ‚úÖ Run MIRI on unsafe code

### Phase 4: Documentation (Week 3)
12. ‚úÖ Update README.md
13. ‚úÖ Update CHANGELOG.md
14. ‚úÖ Add module-level documentation
15. ‚úÖ Create examples/concurrent_usage.rs

### Phase 5: Release (Week 3-4)
16. ‚úÖ Final testing pass
17. ‚úÖ Performance validation
18. ‚úÖ Publish to crates.io

---

## 11. Success Metrics

### Performance Targets

| Metric | Target | Measured By |
|--------|--------|-------------|
| Single-thread overhead | **0%** (no change) | `cargo bench --bench criterion_benchmarks` |
| 8-thread throughput | > 6x single-thread | `cargo bench --bench concurrent_benchmarks` |
| Memory overhead per segment | < 1KB | Manual measurement |

### Quality Targets

- [x] 100% of existing tests pass without modification
- [x] `no_std` build succeeds
- [ ] > 20 new concurrent tests
- [ ] Zero clippy warnings
- [ ] MIRI clean

---

## 12. Risk Mitigation

### Risk: Breaking Existing Users

**Mitigation**: 
- **No API changes to existing types**
- Concurrent types are additive, behind feature flag
- Extensive backwards compatibility testing

### Risk: `no_std` Regression

**Mitigation**:
- CI includes `no_std` build verification
- Concurrent module is `#[cfg(feature = "concurrent")]`
- Default features do not include `concurrent`

### Risk: Code Duplication

**Mitigation**:
- Shared `*Segment` types contain all algorithm logic
- Wrapper types are thin (~50-100 lines each)
- Single point of maintenance for algorithms

### Risk: Deadlocks

**Mitigation**:
- Never hold locks on multiple segments
- Each operation locks exactly one segment
- Lock ordering not required (single lock pattern)

---

## 13. Decisions Made

### Resolved Questions

| Question | Decision | Rationale |
|----------|----------|-----------|
| Segment count default | `min(num_cpus, 32, capacity/64)` | Balance parallelism vs overhead |
| Clone requirement | Only for `Concurrent*Cache::get()` | Single-threaded API unchanged |
| Metrics aggregation | Sum counts, recalculate rates | Correct hit_rate calculation |
| Lock type | `parking_lot::RwLock` | Better performance than std |
| `get()` returns | Clone for concurrent, ref for single | Can't return refs across locks |

### Trade-offs Accepted

1. **Concurrent `get()` requires Clone**: Necessary because references can't cross lock boundaries. Mitigated by `get_with()` callback.

2. **Separate types vs unified API**: Chose separate types (`ConcurrentLruCache`) over unified API to avoid runtime overhead in single-threaded case.

3. **~500 lines of new wrapper code**: Acceptable trade-off for zero code duplication in algorithm logic and preserved `no_std`.

---

## 14. Future Enhancements (Post v0.2.0)

Not included in this spec:

1. **Async Support**: `async fn get()` for tokio/async-std
2. **TTL/Expiration**: Per-item time-to-live
3. **Size-Based Eviction**: Byte-based capacity limits
4. **Sharded Iteration**: Thread-safe iterator support
5. **Custom Hashers**: xxHash, ahash built-in support

---

## Appendix: API Comparison

### Single-Threaded (Unchanged)

```rust
use cache_rs::LruCache;

let mut cache = LruCache::new(capacity);
cache.put("key", "value");

// Returns &V - no clone required
if let Some(value_ref) = cache.get(&"key") {
    println!("{}", value_ref);
}

// Mutable access
if let Some(value_mut) = cache.get_mut(&"key") {
    *value_mut = "new_value";
}
```

### Concurrent (New)

```rust
use cache_rs::concurrent::ConcurrentLruCache;
use std::sync::Arc;

let cache = Arc::new(ConcurrentLruCache::new(capacity));
cache.put("key", "value");

// Returns V (cloned) - required for thread safety
if let Some(value) = cache.get(&"key") {
    println!("{}", value);
}

// Zero-copy with callback
cache.get_with(&"key", |value| {
    println!("{}", value);
});

// Share across threads
let cache_clone = Arc::clone(&cache);
std::thread::spawn(move || {
    cache_clone.get(&"key");
});
```
